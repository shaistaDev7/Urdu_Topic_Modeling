{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"provenance":[]},"accelerator":"TPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"HcX6HdBFiaau"},"source":["###  Train LDA with variational inference on Urdu Datasets with OCTIS\n","\n","Welcome! This is a tutorial that allows you to train a topic model LDA using OCTIS\n","\n","\n","\n","A topic model allows you to discover the latent topics in your documents in a completely unsupervised way.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Dw5Yjfb8VpUF"},"source":["## Mounting Google Drive\n","If the dataset is on Google Drive then you have to mount over google drive with collaboratory."]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kjOfqKNhTKg9","executionInfo":{"status":"ok","timestamp":1698345884237,"user_tz":-300,"elapsed":57057,"user":{"displayName":"SHAISTA ZULFIQAR","userId":"01525964544282656639"}},"outputId":"415e2d45-796f-4a79-9804-a19e312813f3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"RPDPd7BBUuVl"},"source":["\n","#Installing required dependencies\n","First we will install all the required extrnal libraries. installing octis library to train LDA model\n","\n","<b>One thing to remember is that after installing libraries you have to restart the run time again so that other dependencies are not affected by it.</b>"]},{"cell_type":"code","metadata":{"id":"m47oOaBsiRlO","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1698345961737,"user_tz":-300,"elapsed":49129,"user":{"displayName":"SHAISTA ZULFIQAR","userId":"01525964544282656639"}},"outputId":"4a70255c-9895-4e11-d40e-b880c0d41836"},"source":["!pip install octis"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting octis\n","  Downloading octis-1.13.1-py2.py3-none-any.whl (130 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.0/131.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting gensim==4.2.0 (from octis)\n","  Downloading gensim-4.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (24.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.0/24.0 MB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from octis) (3.8.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from octis) (1.5.3)\n","Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (from octis) (3.6.1)\n","Collecting scikit-learn==1.1.0 (from octis)\n","  Downloading scikit_learn-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting scikit-optimize>=0.8.1 (from octis)\n","  Downloading scikit_optimize-0.9.0-py2.py3-none-any.whl (100 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.3/100.3 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from octis) (3.7.1)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from octis) (2.1.0+cu118)\n","Collecting numpy==1.23.0 (from octis)\n","  Downloading numpy-1.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.0/17.0 MB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting libsvm (from octis)\n","  Downloading libsvm-3.23.0.4.tar.gz (170 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.6/170.6 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (from octis) (2.2.5)\n","Collecting sentence-transformers (from octis)\n","  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from octis) (2.31.0)\n","Collecting tomotopy (from octis)\n","  Downloading tomotopy-0.12.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.10/dist-packages (from gensim==4.2.0->octis) (1.11.3)\n","Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim==4.2.0->octis) (6.4.0)\n","Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.1.0->octis) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.1.0->octis) (3.2.0)\n","Collecting pyaml>=16.9 (from scikit-optimize>=0.8.1->octis)\n","  Downloading pyaml-23.9.7-py3-none-any.whl (23 kB)\n","Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from flask->octis) (3.0.1)\n","Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from flask->octis) (3.1.2)\n","Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask->octis) (2.1.2)\n","Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from flask->octis) (8.1.7)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->octis) (1.1.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->octis) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->octis) (4.43.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->octis) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->octis) (23.2)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->octis) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->octis) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->octis) (2.8.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->octis) (2023.6.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->octis) (4.66.1)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->octis) (2023.3.post1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->octis) (3.3.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->octis) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->octis) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->octis) (2023.7.22)\n","Collecting transformers<5.0.0,>=4.6.0 (from sentence-transformers->octis)\n","  Downloading transformers-4.34.1-py3-none-any.whl (7.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m74.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->octis) (0.16.0+cu118)\n","Collecting sentencepiece (from sentence-transformers->octis)\n","  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting huggingface-hub>=0.4.0 (from sentence-transformers->octis)\n","  Downloading huggingface_hub-0.18.0-py3-none-any.whl (301 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->octis) (3.12.4)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->octis) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->octis) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->octis) (3.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->octis) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->octis) (2.1.0)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy->octis) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy->octis) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy->octis) (1.0.10)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->octis) (2.0.8)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->octis) (3.0.9)\n","Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy->octis) (8.1.12)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy->octis) (1.1.2)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy->octis) (2.4.8)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy->octis) (2.0.10)\n","Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy->octis) (0.9.0)\n","Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy->octis) (0.10.3)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy->octis) (1.10.13)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy->octis) (67.7.2)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy->octis) (3.3.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers->octis) (6.0.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->flask->octis) (2.1.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->octis) (1.16.0)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy->octis) (0.7.11)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy->octis) (0.1.3)\n","Collecting tokenizers<0.15,>=0.14 (from transformers<5.0.0,>=4.6.0->sentence-transformers->octis)\n","  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m58.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers<5.0.0,>=4.6.0->sentence-transformers->octis)\n","  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->octis) (1.3.0)\n","Collecting huggingface-hub>=0.4.0 (from sentence-transformers->octis)\n","  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: libsvm, sentence-transformers\n","  Building wheel for libsvm (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for libsvm: filename=libsvm-3.23.0.4-cp310-cp310-linux_x86_64.whl size=251407 sha256=6c2e83b13e7663952dcea4414e654a8fc89992b1085bc59b2626600b6e9a08c6\n","  Stored in directory: /root/.cache/pip/wheels/79/c7/19/a8c85928f8e629654b8e1adb3c8091f0bb77344d0ee9954a85\n","  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125923 sha256=cbadf35b31cd289d4d1a0fd4e2f3fdd6c4f75103f9432975eb3cf193505f3082\n","  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n","Successfully built libsvm sentence-transformers\n","Installing collected packages: sentencepiece, safetensors, pyaml, numpy, libsvm, tomotopy, huggingface-hub, tokenizers, scikit-learn, gensim, transformers, scikit-optimize, sentence-transformers, octis\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.23.5\n","    Uninstalling numpy-1.23.5:\n","      Successfully uninstalled numpy-1.23.5\n","  Attempting uninstall: scikit-learn\n","    Found existing installation: scikit-learn 1.2.2\n","    Uninstalling scikit-learn-1.2.2:\n","      Successfully uninstalled scikit-learn-1.2.2\n","  Attempting uninstall: gensim\n","    Found existing installation: gensim 4.3.2\n","    Uninstalling gensim-4.3.2:\n","      Successfully uninstalled gensim-4.3.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","lida 0.0.10 requires fastapi, which is not installed.\n","lida 0.0.10 requires kaleido, which is not installed.\n","lida 0.0.10 requires python-multipart, which is not installed.\n","lida 0.0.10 requires uvicorn, which is not installed.\n","bigframes 0.10.0 requires scikit-learn>=1.2.2, but you have scikit-learn 1.1.0 which is incompatible.\n","orbax-checkpoint 0.4.1 requires jax>=0.4.9, but you have jax 0.3.25 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed gensim-4.2.0 huggingface-hub-0.17.3 libsvm-3.23.0.4 numpy-1.23.0 octis-1.13.1 pyaml-23.9.7 safetensors-0.4.0 scikit-learn-1.1.0 scikit-optimize-0.9.0 sentence-transformers-2.2.2 sentencepiece-0.1.99 tokenizers-0.14.1 tomotopy-0.12.5 transformers-4.34.1\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy"]}}},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"MrBRkDYBWDYg"},"source":["\n","# Importing required dependencies\n","We will import numpy, pandas, octis library. other libraries will be imported in the notebook later.\n","\n","Pandas will be used to create a Dataframe and handle the csv file. Numpy will be used for the faster computation of arrays to save time. octis library is used to train LDA model and then evaluate result using topic diversity and coherence score with the help of octis library"]},{"cell_type":"markdown","metadata":{"id":"TGi97q6Pj1iL"},"source":["Let's import what we need."]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np"],"metadata":{"id":"AHOv8us_Hu3K"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xgmokdyEiRlV"},"source":["from octis.models.LDA import LDA\n","from octis.dataset.dataset import Dataset\n","from octis.evaluation_metrics.diversity_metrics import TopicDiversity\n","from octis.evaluation_metrics.coherence_metrics import Coherence"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nJWNy-ulj-H7"},"source":["## Dataframe\n","We need some data to run a topic model. to load custom preprocessed dataset must be following format.\n","1. corpus file: a .tsv file (tab-separated) that contains up to three columns, i.e. the document, the partitition, and the label associated to the document (optional).\n","2. vocabulary: a .txt file where each line represents a word of the vocabulary"]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"Zv05olCwiRlW"},"source":["# Load folder of dataset which contain corpus.tsv file and vocabulary.txt file\n","dataset = Dataset()\n","dataset.load_custom_dataset_from_folder('/content/drive/MyDrive/octis_format_UNTM/Classical') #add your repository here"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data = dataset.get_corpus()\n","print(data[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UJE7r3dNzGyJ","executionInfo":{"status":"ok","timestamp":1698346038874,"user_tz":-300,"elapsed":438,"user":{"displayName":"SHAISTA ZULFIQAR","userId":"01525964544282656639"}},"outputId":"c627b52b-f2e3-4fee-cd77-a78f3f5d194e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['بھارتی', 'کرکٹ', 'آئیکون', 'ویرات', 'کوہلی', 'انکی', 'سپر', 'سٹار', 'اہلیہ', 'انوشکا', 'شرما', 'بیڈ', 'منٹن', 'کھیلتے', 'ویڈیو', 'سوشل', 'میڈیا', 'وائرل', 'ہوگئی۔بھارتی', 'میڈیا', 'مطابق', 'ویرات', 'کوہلی', 'انوشکا', 'شرما', 'پوما', 'پروموشنل', 'ایونٹ', 'پہنچے', 'ساتھ', 'بیڈ', 'منٹن', 'کھیلا۔جس', 'ویڈیو', 'تصاویر', 'سوشل', 'میڈیا', 'وائرل', 'گئی۔', 'ویرات', 'کوہلی', 'انوشکا', 'شرما', 'اکثر', 'فٹنس', 'وابستگی', 'روزمرہ', 'زندگی', 'کھیلوں', 'اہمیت', 'اجاگرکرتے', 'نظر', 'آتے', 'مقبولیت', 'روز', 'دن', 'اضافہ', 'ہے۔']\n"]}]},{"cell_type":"markdown","metadata":{"id":"ky2sTIyIlO28"},"source":["##Train LDA\n","Now we're ready to train it. See that the output of a topic model comes as a dictionary composed of 4 elements:\n","\n","\n","*   *topics*: the list of word topics\n","*   *topic-word-matrix*: the distribution of the words of the vocabulary for each topic (dimensions: |num topics| x |vocabulary|)\n","*   *topic-document-matrix*: the distribution of the topics for each document of the training set (dimensions: |num topics| x |training documents|)\n","*   *test-document-topic-matrix*: the distribution of the topics for each document of the testing set (dimensions: |num topics| x |test documents|)\n","\n"]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"CC5N5nLBiRlW"},"source":["# Create Model\n","model = LDA(num_topics=7, iterations=3500, alpha=0.01, eta=0.01, random_state=15)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R_mboM91iRlX","colab":{"base_uri":"https://localhost:8080/"},"outputId":"fd727a25-d9a2-4b8e-81bc-45c934d56d6e","executionInfo":{"status":"ok","timestamp":1698346394942,"user_tz":-300,"elapsed":36727,"user":{"displayName":"SHAISTA ZULFIQAR","userId":"01525964544282656639"}}},"source":["# Train the model using default partitioning choice\n","output = model.train_model(dataset)\n","\n","print(*list(output.keys()), sep=\"\\n\") # Print the output identifiers"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"]},{"output_type":"stream","name":"stdout","text":["topic-word-matrix\n","topics\n","topic-document-matrix\n","test-topic-document-matrix\n"]}]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"k9PIWegniRlY","colab":{"base_uri":"https://localhost:8080/"},"outputId":"49617782-6937-4ab7-bc6d-e5efff3c1d5e","executionInfo":{"status":"ok","timestamp":1698346513815,"user_tz":-300,"elapsed":534,"user":{"displayName":"SHAISTA ZULFIQAR","userId":"01525964544282656639"}}},"source":["#print topics\n","for t in output['topics'][:7]:\n","  print(\" \".join(t))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ہے۔ صارفین سال فی روپے ویڈیو میڈیا ساتھ شادی کرونا\n","پاکستان ہے۔ خان عمران مطابق حکومت ساتھ وزیراعظم ٹی انصاف\n","کورونا وائرس صحت ہے۔ مریض افراد مریضوں ہیں۔ ہسپتال فیصد\n","ہے۔ کورونا ویکسین ہزار مطابق وائرس انسداد قطرے ہیں۔ ساتھ\n","خان عمران ہے۔ فلم میڈیا مطابق ہیں۔ شاہ فیس ساتھ\n","پنجاب ڈاکٹر ہے۔ ساتھ اینڈ چیمبر ٹی موقع محمد ڈپٹی\n","پی پاکستان سی ٹی مطابق ہے۔ ڈی ہزار آئی فیصل\n"]}]},{"cell_type":"markdown","metadata":{"id":"FvXXTwglo76N"},"source":["# Evaluation\n","we used three evaluation metrics to compare the reults obtained from Model.\n","\n","1. The coherence score is used to capture the degree of similarity between the words within each topic, with higher scores indicating more coherent topics\n","2. Topic diversity measures are used to assess how different and distinct the topics are in a topic model.\n"]},{"cell_type":"markdown","source":["**Coherence Score**"],"metadata":{"id":"FekP45FlVa1B"}},{"cell_type":"code","metadata":{"id":"e8uXU4_hrE3G"},"source":["# Initialize metric\n","cs = Coherence(texts=dataset.get_corpus(), topk=10, measure='c_npmi') #use c_v and c_npmi for coherence score"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8Itz2zvHmGVe"},"source":["**Diversity Score**\n","\n","Or we can test if the resulting topics are different from each other. The `InvertedRBO` measure computes the number of unique words.\n","\n"]},{"cell_type":"markdown","source":["**Inverted Rank Biased Overlap**"],"metadata":{"id":"-7kDuny_WDic"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"as7m08DWHLa3"},"outputs":[],"source":["from octis.evaluation_metrics.diversity_metrics import InvertedRBO"]},{"cell_type":"code","source":["# Initialize metric\n","IRBO = InvertedRBO(topk=10, weight=0.9)"],"metadata":{"id":"xNerMkuqJCBz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Retrieve metrics score\n","IRBO_score = IRBO.score(output)\n","print(\"Inverted RBO: \"+str(IRBO_score))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eQCbnDfVJP84","executionInfo":{"status":"ok","timestamp":1698346756972,"user_tz":-300,"elapsed":476,"user":{"displayName":"SHAISTA ZULFIQAR","userId":"01525964544282656639"}},"outputId":"ad0d602b-7a07-4d69-e61c-569da3c65338"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Inverted RBO: 0.7967834594880953\n"]}]},{"cell_type":"markdown","source":["# LDA on UDC"],"metadata":{"id":"QexUlQdahIvJ"}},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"qc9F3KZ-hgs0"},"source":["# Define dataset\n","dataset1 = Dataset()\n","dataset1.load_custom_dataset_from_folder('/content/drive/MyDrive/octis_format_UDC/Classical')"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data = dataset1.get_corpus()\n","print(data[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698347062294,"user_tz":-300,"elapsed":744,"user":{"displayName":"SHAISTA ZULFIQAR","userId":"01525964544282656639"}},"outputId":"b446f13c-8fee-4b0b-e4b7-c1069dc0d64d","id":"L2YS2WmVhgs0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['اسلام', 'آباد', 'ایسوسی', 'ایشن', 'آف', 'چارٹرڈ', 'سرٹیفائیڈاکاؤئنٹنٹس', 'ٹیکس', 'نظام', 'سنجیدگی', 'جانچ', 'پڑتال', 'ضرورت', 'ٹیکس', 'دہندگان', 'عوام', 'ٹیکس', 'حکام', 'اعتماد', 'انتہائی', 'نتیجے', 'ٹیکس', 'چوری', 'باعث', 'قومی', 'خزانہ', 'اربوں', 'روپے', 'نقصان', 'اے', 'سی', 'سی', 'اے', 'جانب', 'جمع', 'کرائی', 'ٹیکس', 'تجاویز', 'ٹیکس', 'شرح', 'یک', 'ہندسی', 'ڈائریکٹ', 'ٹیکسیشن', 'رفتار', 'اضافے', 'نادرا', 'ڈیٹا', 'بیس', 'ودہولڈنگ', 'ٹیکس', 'ڈیٹا', 'استعمال', 'اثاثہ', 'جات', 'تشخیص', 'شامل', 'ہیں۔', 'اے', 'سی', 'سی', 'اے', 'اسٹرکچرل', 'ریفارمز', 'ٹیکس', 'دہندہ', 'تمام', 'ٹیکس', 'امور', 'کیلیے', 'ٹیکس', 'ریٹرن', 'تجویز', 'کیاگیا', 'تجاویز', 'کہاگیا', 'پاکستان', 'ٹیکس', 'ٹو', 'جی', 'ڈی', 'پی', 'شرح', 'خطے', 'کارپوریٹ', 'ٹیکس', 'شرح', 'فیصد', 'بلند', 'سطح', 'ٹیکس', 'حکام', 'ضرورت', 'سیلز', 'ٹیکس', 'خطے', 'انتہائی', 'بلند', 'فیصد', 'ایشیا', 'اوسطاً', 'فیصد', 'قریب', 'سیلز', 'ٹیکس', 'براہ', 'راست', 'ٹیکس', 'متبادل', 'بجائے', 'ٹیکس', 'بیس', 'توسیع', 'کیلیے', 'استعمال', 'چاہیے۔']\n"]}]},{"cell_type":"markdown","source":["**Train Model**"],"metadata":{"id":"LJe7bXK7XCmH"}},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"LJLLmJwGhgs1"},"source":["# Create Model\n","model1 = LDA(num_topics=5, iterations=3500, alpha=0.01, eta=0.01, random_state=15)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"fb1e26c5-2357-4d49-f825-7157cc095f04","executionInfo":{"status":"ok","timestamp":1698347265115,"user_tz":-300,"elapsed":19019,"user":{"displayName":"SHAISTA ZULFIQAR","userId":"01525964544282656639"}},"id":"Cixn-hkghgs1"},"source":["# Train the model using default partitioning choice\n","output1 = model1.train_model(dataset1)\n","\n","print(*list(output1.keys()), sep=\"\\n\") # Print the output identifiers"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"]},{"output_type":"stream","name":"stdout","text":["topic-word-matrix\n","topics\n","topic-document-matrix\n","test-topic-document-matrix\n"]}]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"f38bc817-adac-4735-86e0-07b6c3504167","executionInfo":{"status":"ok","timestamp":1698347319857,"user_tz":-300,"elapsed":499,"user":{"displayName":"SHAISTA ZULFIQAR","userId":"01525964544282656639"}},"id":"2HRbGljChgs2"},"source":["for t in output1['topics'][:5]:\n","  print(\" \".join(t))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ہے۔ ہیں۔ پاکستان ساتھ جانب علی سال کوئی مطابق سی\n","ہے۔ ہیں۔ کینسر پاکستان ساتھ سال سی مطابق استعمال ٹی\n","ہے۔ ہیں۔ ساتھ فلم پاکستان خان سال کراچی مطابق کیلیے\n","ہے۔ ہیں۔ ٹیکس فیصد سال حکومت سی ساتھ مطابق آئی\n","ہے۔ روپے ہیں۔ پانی پاکستان ساتھ مطابق کیلیے استعمال فی\n"]}]},{"cell_type":"markdown","source":["**Coherence Score**"],"metadata":{"id":"CzsJ1B47XPmb"}},{"cell_type":"code","metadata":{"id":"-Mk0enPChgs2"},"source":["# Initialize metric\n","coh = Coherence(texts=dataset1.get_corpus(), topk=10, measure='c_npmi')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Diversity Score**"],"metadata":{"id":"_eQu_hw1XYxG"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"mDTDA4CKhgs3"},"outputs":[],"source":["from octis.evaluation_metrics.diversity_metrics import InvertedRBO"]},{"cell_type":"code","source":["# Initialize metric\n","IRBO1 = InvertedRBO(topk=10, weight=0.9)"],"metadata":{"id":"sXCK_Qhthgs3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Retrieve metrics score\n","IRBO_score1 = IRBO1.score(output1)\n","print(\"Inverted RBO: \"+str(IRBO_score1))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698347533298,"user_tz":-300,"elapsed":472,"user":{"displayName":"SHAISTA ZULFIQAR","userId":"01525964544282656639"}},"outputId":"663cea69-41ce-488c-dfc4-282d0bb16571","id":"X2m22auihgs4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Inverted RBO: 0.3608013534557144\n"]}]}]}